config_file=./BERT/data/roberta_zh_l12/bert_config.json
init_checkpoint=roberta_zh_l12/bert_model.ckpt
vocab_file=./BERT/data/roberta_zh_l12/vocab.txt
label_id=./BERT/data/lcqmc/label_dict.json
max_length=130
train_file=nlpcc2019/chid/data_crf/train_tfrecords_crf
dev_file=nlpcc2019/chid/data_crf/dev_tfrecords_crf
model_output=nlpcc2019/chid/data_crf/model/estimator/bert_chid_crf_20190914/
epoch=5
num_classes=11
train_size=76238
eval_size=8471
batch_size=3
model_type=bert
num_gpus=4
if_shard=2
is_debug=1
run_type=estimator
parse_type=parse_batch
rule_model=normal
profiler="no"
train_op=adam_weight_decay_exclude
running_type=train
cross_tower_ops_type=paisoar
opt_type="all_reduce"
distribution_strategy=MirroredStrategy
load_pretrained=yes
warmup=warmup
decay=decay
with_target=""
input_target=""
distillation="normal"
temperature=2.0
distillation_ratio=1.0
num_hidden_layers=12
task_type=bert_chid_crf
classifier=order_classifier
max_predictions_per_seq=10
mode="single_task"