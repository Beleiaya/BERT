config_file=./BERT/data/roberta_zh_l12_albert/bert_config_tiny.json
init_checkpoint=""
vocab_file=./BERT/data/roberta_zh_l12_albert/vocab.txt
label_id=./BERT/data/lcqmc/label_dict.json
max_length=512
train_file=bert_pretrain/open_domain/pretrain_new/chunk_0.tfrecords,bert_pretrain/open_domain/pretrain_new/chunk_1.tfrecords,bert_pretrain/open_domain/pretrain_new/chunk_2.tfrecords,bert_pretrain/open_domain/pretrain_new/chunk_3.tfrecords,bert_pretrain/open_domain/pretrain_new/chunk_4.tfrecords,bert_pretrain/open_domain/pretrain_new/chunk_5.tfrecords,bert_pretrain/open_domain/pretrain_new/chunk_6.tfrecords,bert_pretrain/open_domain/pretrain_new/chunk_7.tfrecords,bert_pretrain/open_domain/pretrain_new/chunk_8.tfrecords,bert_pretrain/open_domain/pretrain_new/chunk_9.tfrecords,bert_pretrain/open_domain/pretrain_new/chunk_10.tfrecords,bert_pretrain/open_domain/pretrain_new/chunk_11.tfrecords,bert_pretrain/open_domain/pretrain_new/chunk_12.tfrecords,bert_pretrain/open_domain/pretrain_new/chunk_13.tfrecords,bert_pretrain/open_domain/pretrain_new/chunk_14.tfrecords,bert_pretrain/open_domain/pretrain_new/chunk_15.tfrecords,bert_pretrain/open_domain/pretrain_new/chunk_16.tfrecords,bert_pretrain/open_domain/pretrain_new/chunk_17.tfrecords,bert_pretrain/open_domain/pretrain_new/chunk_18.tfrecords,bert_pretrain/open_domain/pretrain_new/chunk_19.tfrecords
dev_file=bert_pretrain/open_domain/pretrain_new/chunk_10.tfrecords,bert_pretrain/open_domain/pretrain_new/chunk_11.tfrecords,bert_pretrain/open_domain/pretrain_new/chunk_12.tfrecords,bert_pretrain/open_domain/pretrain_new/chunk_13.tfrecords,bert_pretrain/open_domain/pretrain_new/chunk_14.tfrecords,bert_pretrain/open_domain/pretrain_new/chunk_15.tfrecords,bert_pretrain/open_domain/pretrain_new/chunk_16.tfrecords,bert_pretrain/open_domain/pretrain_new/chunk_17.tfrecords,bert_pretrain/open_domain/pretrain_new/chunk_18.tfrecords,bert_pretrain/open_domain/pretrain_new/chunk_19.tfrecords
model_output=bert_pretrain/open_domain/pretrain_new/model/open_domain_abert_tiny_projection_no_grad_clip_preln_1e-4/
epoch=50
num_classes=2
train_size=12000000
eval_size=8802
batch_size=24
model_type=albert
if_shard=1
is_debug=1
run_type=estimator
opt_type="collective_reduce"
num_gpus=4
parse_type=parse_batch
rule_model=normal
profiler="no"
train_op=adam
running_type=train
cross_tower_ops_type=paisoar
distribution_strategy=CollectiveAllReduceStrategy
load_pretrain_newed=no
warmup=warmup
decay=decay
with_target=""
input_target=""
distillation="normal"
temperature=2.0
distillation_ratio=1.0
num_hidden_layers=12
task_type=bert_pretrain
classifier=order_classifier
max_predictions_per_seq=78
ln_type=preln
